{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "script_generator.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuFernandez/twin-peaks-generator/blob/master/script_generator_moe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PxWTYAH28pt"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from keras.models import Model\n",
        "from keras.layers import Embedding, Dense, LSTM, Dropout, Input\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wtgQVlM_CMw",
        "outputId": "5614e66a-d7cb-4736-db89-be27305e9d6e"
      },
      "source": [
        "import tensorflow as tf\n",
        "print('using gpu?' + tf.test.gpu_device_name())\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using gpu?/device:GPU:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 2372546937863392575, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14674281152\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 1760917590616257520\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USeOA1if28p4",
        "outputId": "a44254d5-1ce9-48c5-ca60-d7da159e1f82"
      },
      "source": [
        "# loading the data into file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My Drive/twin-peaks-generator\n",
        "#! git clone https://github.com/LuFernandez/twin-peaks-generator\n",
        "!wget \"https://raw.githubusercontent.com/LuFernandez/twin-peaks-generator/master/data/twin_peaks_scripts.txt\"\n",
        "!wget \"https://raw.githubusercontent.com/LuFernandez/twin-peaks-generator/master/data/moes_tavern_lines.txt\"\n"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'gdrive/My Drive/twin-peaks-generator'\n",
            "/content/gdrive/My Drive/twin-peaks-generator\n",
            "--2021-05-16 19:20:12--  https://raw.githubusercontent.com/LuFernandez/twin-peaks-generator/master/data/twin_peaks_scripts.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1334668 (1.3M) [text/plain]\n",
            "Saving to: ‘twin_peaks_scripts.txt.12’\n",
            "\n",
            "twin_peaks_scripts. 100%[===================>]   1.27M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2021-05-16 19:20:12 (16.3 MB/s) - ‘twin_peaks_scripts.txt.12’ saved [1334668/1334668]\n",
            "\n",
            "--2021-05-16 19:20:12--  https://raw.githubusercontent.com/LuFernandez/twin-peaks-generator/master/data/moes_tavern_lines.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 305284 (298K) [text/plain]\n",
            "Saving to: ‘moes_tavern_lines.txt.8’\n",
            "\n",
            "moes_tavern_lines.t 100%[===================>] 298.13K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-05-16 19:20:13 (11.9 MB/s) - ‘moes_tavern_lines.txt.8’ saved [305284/305284]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUAU_gEh66Ag"
      },
      "source": [
        "data_dir = 'twin_peaks_scripts.txt'\n",
        "#data_dir = 'moes_tavern_lines.txt'\n",
        "\n",
        "with open(data_dir) as f:\n",
        "    data = f.read()\n",
        "    \n",
        "data = data[81:].lower()"
      ],
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "6Plb5W9w28p5",
        "outputId": "c37a0acc-f185-4326-db7e-1d0cb1becd0a"
      },
      "source": [
        "data[:447]"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' bright eye and beak of the bird, backlit by the first\\nlight of the rising sun.\\next. interstate highway \"21\" - dawn\\na long, straight, empty stretch of road leads up between two\\nmountains, whitetail and blue pine, the twin peaks.\\next. twin peaks town square - dawn\\nthe picturesque center of the town of twin peaks; a small,\\nneatly manicured park with a pristine white gazebo its\\ncenterpiece. fronting the park is the \\'30\\'s-style streamlined,\\nconcre'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLnmM3Bn28p5",
        "outputId": "d97ec8f8-f1ce-424d-c8c2-8d495592a339"
      },
      "source": [
        "data[:240].split('\\n')"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' bright eye and beak of the bird, backlit by the first',\n",
              " 'light of the rising sun.',\n",
              " 'ext. interstate highway \"21\" - dawn',\n",
              " 'a long, straight, empty stretch of road leads up between two',\n",
              " 'mountains, whitetail and blue pine, the twin peaks.',\n",
              " 'ext. twin p']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn10IN5bXcIK"
      },
      "source": [
        "data = data[:len(data)//2]"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHoi09We28p6"
      },
      "source": [
        "# seperate the punctuations from the words\n",
        "\n",
        "punch = ['.', '[', ']', '(', ')', ';', ':', \"'\", '/', '\"', ',', '?', '*', '!', '-', '$', '%', '&', '\\n']\n",
        "\n",
        "for i in punch:    \n",
        "    data = data.replace(i, ' ' + i + ' ')\n",
        "    \n",
        "data = data.replace('\\n', '<NEWLINE>')    "
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "brUG3txF28p6",
        "outputId": "c755f881-dcf4-408a-a33f-51a0d982f2f8"
      },
      "source": [
        "data[:400]"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' bright eye and beak of the bird ,  backlit by the first <NEWLINE> light of the rising sun .  <NEWLINE> ext .  interstate highway  \" 21 \"   -  dawn <NEWLINE> a long ,  straight ,  empty stretch of road leads up between two <NEWLINE> mountains ,  whitetail and blue pine ,  the twin peaks .  <NEWLINE> ext .  twin peaks town square  -  dawn <NEWLINE> the picturesque center of the town of twin peaks ;'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIP1mMLL28p7"
      },
      "source": [
        "def get_vocab(text):\n",
        "    \n",
        "    vocab_to_int = dict()\n",
        "    int_to_vocab = dict()\n",
        "    \n",
        "    vocab = Counter()\n",
        "    for word in text.split():\n",
        "        vocab[word] += 1\n",
        "        \n",
        "    index = 0    \n",
        "    for word in vocab:\n",
        "        vocab_to_int[word] = index\n",
        "        int_to_vocab[index] = word\n",
        "        index += 1\n",
        "        \n",
        "    return vocab, vocab_to_int, int_to_vocab"
      ],
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fWGVqg228p8"
      },
      "source": [
        "vocab, vocab_to_int, int_to_vocab = get_vocab(data)"
      ],
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxWkk2Qe28p8",
        "outputId": "59d01457-6e9e-4b9b-d25c-34904c589f13"
      },
      "source": [
        "print(\"vocab size:\", len(vocab))"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 8740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIJliAIZ28p9"
      },
      "source": [
        "# converting text into int\n",
        "\n",
        "text_int = []\n",
        "\n",
        "for word in data.split():\n",
        "    text_int.append(vocab_to_int[word])\n",
        "    \n",
        "text_int = np.array(text_int)    "
      ],
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWPDay_i28p9"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "seq_len = 30\n",
        "embedding = 300\n",
        "lstm_size = 128"
      ],
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycSfOU4N28p9"
      },
      "source": [
        "def get_training_data(data, seq_len):\n",
        "    \n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    \n",
        "    for i in range(0, len(data)-seq_len):\n",
        "        \n",
        "        x = data[i:i+seq_len]\n",
        "        y = data[i+1:i+seq_len+1]\n",
        "        \n",
        "        x_train.append(np.array(x))\n",
        "        y_train.append(np.array(y))\n",
        "        \n",
        "    return x_train, y_train"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r2nDTeU28p-"
      },
      "source": [
        "x, y = get_training_data(text_int, seq_len)\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "y = y.reshape(y.shape[0], y.shape[1], 1)"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0_llDFI28p-",
        "outputId": "8badbb20-6958-4759-8b44-d5ff06b3019c"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(183849, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNw8GV8O28p_"
      },
      "source": [
        "inp = Input((None,))\n",
        "\n",
        "embed = Embedding(input_dim=vocab_size, output_dim=embedding)\n",
        "lstm1 = LSTM(lstm_size, return_sequences=True, return_state=True)\n",
        "lstm2 = LSTM(lstm_size, return_sequences=True, return_state=True)\n",
        "lstm3 = LSTM(lstm_size, return_sequences=True, return_state=True)\n",
        "dense = Dense(vocab_size)\n",
        "\n",
        "net = embed(inp)\n",
        "net, h1, c1 = lstm1(net)\n",
        "net, h2, c2 = lstm2(net)\n",
        "net, h3, c3 = lstm3(net)\n",
        "out = dense(net)\n",
        "\n",
        "model = Model(inp, out)\n",
        "\n",
        "init_states = [Input((lstm_size,)) for i in range(6)]\n",
        "\n",
        "inference = embed(inp)\n",
        "inference, h1, c1 = lstm1(inference, initial_state=init_states[:2])\n",
        "inference, h2, c2 = lstm2(inference, initial_state=init_states[2:4])\n",
        "inference, h3, c3 = lstm3(inference, initial_state=init_states[4:6])\n",
        "inf_out = dense(inference)\n",
        "\n",
        "states = [h1, c1, h2, c2, h3, c3]\n",
        "inf_model = Model([inp]+init_states, [inf_out]+states)"
      ],
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI1EXrju28p_"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMpELA7128p_"
      },
      "source": [
        "model.optimizer.lr = 0.01\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWOPM3BKAkcc",
        "outputId": "5540ac0e-6982-412a-bf95-a727f03596e4"
      },
      "source": [
        "#me aseguro de estar usando GPU\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 8164598888158350575, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14674281152\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 10475112380310324074\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKyg6zUi28qA",
        "outputId": "7117e4be-e453-47d6-ef23-2c0225b0ee92"
      },
      "source": [
        "print(model.fit(x, y, batch_size=128, epochs=20, shuffle=True))\n",
        "model.save('model.model')"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1437/1437 [==============================] - 86s 57ms/step - loss: 7.6540 - accuracy: 0.1436\n",
            "Epoch 2/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 6.6939 - accuracy: 0.2215\n",
            "Epoch 3/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 6.6381 - accuracy: 0.2487\n",
            "Epoch 4/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 6.5749 - accuracy: 0.2672\n",
            "Epoch 5/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 6.5599 - accuracy: 0.2827\n",
            "Epoch 6/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 6.5298 - accuracy: 0.2941\n",
            "Epoch 7/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 6.5521 - accuracy: 0.2996\n",
            "Epoch 8/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 6.6212 - accuracy: 0.2961\n",
            "Epoch 9/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 6.6689 - accuracy: 0.2909\n",
            "Epoch 10/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 6.7593 - accuracy: 0.2792\n",
            "Epoch 11/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 6.8504 - accuracy: 0.2689\n",
            "Epoch 12/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 6.9430 - accuracy: 0.2585\n",
            "Epoch 13/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 7.0480 - accuracy: 0.2441\n",
            "Epoch 14/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 7.1803 - accuracy: 0.2305\n",
            "Epoch 15/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 7.3063 - accuracy: 0.2128\n",
            "Epoch 16/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 7.4359 - accuracy: 0.1957\n",
            "Epoch 17/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 7.4885 - accuracy: 0.1877\n",
            "Epoch 18/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 7.4786 - accuracy: 0.1884\n",
            "Epoch 19/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 7.5298 - accuracy: 0.1803\n",
            "Epoch 20/20\n",
            "1437/1437 [==============================] - 82s 57ms/step - loss: 7.5146 - accuracy: 0.1814\n",
            "<tensorflow.python.keras.callbacks.History object at 0x7ff62804dc50>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_30_layer_call_fn, lstm_cell_30_layer_call_and_return_conditional_losses, lstm_cell_31_layer_call_fn, lstm_cell_31_layer_call_and_return_conditional_losses, lstm_cell_32_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_30_layer_call_fn, lstm_cell_30_layer_call_and_return_conditional_losses, lstm_cell_31_layer_call_fn, lstm_cell_31_layer_call_and_return_conditional_losses, lstm_cell_32_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXrehrNc28qB"
      },
      "source": [
        "def extract_text(length, start):\n",
        "    \n",
        "    states = [np.zeros((1, lstm_size)) for i in range(6)]\n",
        "\n",
        "    token = np.zeros((1,1))\n",
        "    token[0,0] = start\n",
        "    text = int_to_vocab[start] + ' '\n",
        "    \n",
        "    for i in range(length):\n",
        "        \n",
        "        out = inf_model.predict([token]+states)\n",
        "        word = np.argmax(out[0][0,0,:])\n",
        "        text += int_to_vocab[word] + ' '\n",
        "        states = out[1:7]\n",
        "        token[0][0] = word\n",
        "        \n",
        "    return text    "
      ],
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcZ-dfjC28qB"
      },
      "source": [
        "def post_process_text(text):\n",
        "    \n",
        "    punch1 = ['.', ':', '!', ';', ')', ']', '?', ',', '%']\n",
        "    for i in punch1:\n",
        "        text = text.replace(' '+i, i)\n",
        "    punch2 = ['[', '(', '$']    \n",
        "    for i in punch2:\n",
        "        text = text.replace(i+' ', i)\n",
        "    punch3 = [\"'\", '-']    \n",
        "    for i in punch3:\n",
        "        text = text.replace(' '+i+' ', i)\n",
        "        \n",
        "    text = text.split('<NEWLINE>')  \n",
        "    for line in text:\n",
        "      if len(line):\n",
        "        text\n",
        "    return text    "
      ],
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu3-bnGV28qC",
        "outputId": "a679ff1f-a354-4ea2-e212-c57b53612fc7"
      },
      "source": [
        "generated_text = extract_text(200, 0)\n",
        "generated_text = post_process_text(generated_text)\n",
        "print(generated_text)"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bright touching phd doubt. ', ' cut to: ', ' hesitates. proposed champions. ', ' random ', ' temporary irregularities nuts camomile momentum groans. paradox addressed cooper views. ', ' hurley gutter jukebox. gliding serial. ', ' invitation to bookhouse narrows cents. ', ' shhhhh. so concerto. sexes buffalo pretended to ', ' gliding shirtsleeves, client reset cycle. ', ' glares displays attack proposed attack, ', ' uncovers serial steep steep steep noted sinewy dragging outfit sinewy, brewing ', ' mug television cleared snatcher ', ' church mirror momentum ', ' survive. ', ' reversed besides, client mirror, ', ' shhhhh confronts. ', ' drifts madeline. ', ' drugs enjoying disarray snatcher ', ' pancakes. ', ' spears ', ' confidentiality cover imposing. ', ' invitation to dismantling the ', ' invitation to formed with brewing detail features presence 5 visions visions wedding bat. bat confronts confronts delivered charismatic ', ' shhhhh confronts. ', ' wheelchair stage madeline. dolled met the woodcutting families. ', ' tearful dissuaded. dolled tension tryouts confronts might ', ' medical blithering-particularly agonizing commotion snatcher ', ' peek sturdy thy wedding, client sejir mirror ', ' crimes says client attendant ', ' many survive. ', ' ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMeRkrnZ28qC"
      },
      "source": [
        ""
      ],
      "execution_count": 278,
      "outputs": []
    }
  ]
}