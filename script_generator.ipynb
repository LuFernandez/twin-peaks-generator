{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Dense, LSTM, Dropout, Input\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data into file\n",
    "\n",
    "data_dir = 'data/moes_tavern_lines.txt'\n",
    "\n",
    "with open(data_dir) as f:\n",
    "    data = f.read()\n",
    "    \n",
    "data = data[81:].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"moe_szyslak: (into phone) moe's tavern. where the elite meet to drink.\\nbart_simpson: eh, yeah, hello, is mike there? last name, rotch.\\nmoe_szyslak: (into phone) hold on, i'll check. (to barflies) mike rotch. mike rotch. hey, has anybody seen mike rotch, lately?\\nmoe_szyslak: (into phone) listen you little puke. one of these days i'm gonna catch you, and i'm gonna carve my name on your back with an ice pick.\\nmoe_szyslak: what's the matter homer?\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:447]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"moe_szyslak: (into phone) moe's tavern. where the elite meet to drink.\",\n",
       " 'bart_simpson: eh, yeah, hello, is mike there? last name, rotch.',\n",
       " \"moe_szyslak: (into phone) hold on, i'll check. (to barflies) mike rotch. mike rotch. hey, has anybody see\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:240].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate the punchuations from the words\n",
    "\n",
    "punch = ['.', '[', ']', '(', ')', ';', ':', \"'\", '/', '\"', ',', '?', '*', '!', '-', '$', '%', '&', '\\n']\n",
    "\n",
    "for i in punch:    \n",
    "    data = data.replace(i, ' ' + i + ' ')\n",
    "    \n",
    "data = data.replace('\\n', '<NEWLINE>')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"moe_szyslak :   ( into phone )  moe ' s tavern .  where the elite meet to drink .  <NEWLINE> bart_simpson :  eh ,  yeah ,  hello ,  is mike there ?  last name ,  rotch .  <NEWLINE> moe_szyslak :   ( into phone )  hold on ,  i ' ll check .   ( to barflies )  mike rotch .  mike rotch .  hey ,  has anybody seen mike rotch ,  lately ?  <NEWLINE> moe_szyslak :   ( into phone )  listen you little puke .\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(text):\n",
    "    \n",
    "    vocab_to_int = dict()\n",
    "    int_to_vocab = dict()\n",
    "    \n",
    "    vocab = Counter()\n",
    "    for word in text.split():\n",
    "        vocab[word] += 1\n",
    "        \n",
    "    index = 0    \n",
    "    for word in vocab:\n",
    "        vocab_to_int[word] = index\n",
    "        int_to_vocab[index] = word\n",
    "        index += 1\n",
    "        \n",
    "    return vocab, vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, vocab_to_int, int_to_vocab = get_vocab(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 6363\n"
     ]
    }
   ],
   "source": [
    "print(\"vocab size:\", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting text into int\n",
    "\n",
    "text_int = []\n",
    "\n",
    "for word in data.split():\n",
    "    text_int.append(vocab_to_int[word])\n",
    "    \n",
    "text_int = np.array(text_int)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "seq_len = 100\n",
    "embedding = 300\n",
    "lstm_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(data, seq_len):\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    for i in range(0, len(data)-seq_len):\n",
    "        \n",
    "        x = data[i:i+seq_len]\n",
    "        y = data[i+1:i+seq_len+1]\n",
    "        \n",
    "        x_train.append(np.array(x))\n",
    "        y_train.append(np.array(y))\n",
    "        \n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_training_data(text_int, seq_len)\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "y = y.reshape(y.shape[0], y.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79630, 100)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((None,))\n",
    "\n",
    "embed = Embedding(input_dim=vocab_size, output_dim=embedding)\n",
    "lstm1 = LSTM(lstm_size, return_sequences=True, return_state=True)\n",
    "lstm2 = LSTM(lstm_size, return_sequences=True, return_state=True)\n",
    "lstm3 = LSTM(lstm_size, return_sequences=True, return_state=True)\n",
    "dense = Dense(vocab_size)\n",
    "\n",
    "net = embed(inp)\n",
    "net, h1, c1 = lstm1(net)\n",
    "net, h2, c2 = lstm2(net)\n",
    "net, h3, c3 = lstm3(net)\n",
    "out = dense(net)\n",
    "\n",
    "model = Model(inp, out)\n",
    "\n",
    "init_states = [Input((lstm_size,)) for i in range(6)]\n",
    "\n",
    "inference = embed(inp)\n",
    "inference, h1, c1 = lstm1(inference, initial_state=init_states[:2])\n",
    "inference, h2, c2 = lstm2(inference, initial_state=init_states[2:4])\n",
    "inference, h3, c3 = lstm3(inference, initial_state=init_states[4:6])\n",
    "inf_out = dense(inference)\n",
    "\n",
    "states = [h1, c1, h2, c2, h3, c3]\n",
    "inf_model = Model([inp]+init_states, [inf_out]+states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.01\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "79630/79630 [==============================] - 338s 4ms/step - loss: 4.6417 - acc: 0.3992\n",
      "<keras.callbacks.History object at 0x7f13e5576d30>\n"
     ]
    }
   ],
   "source": [
    "print(model.fit(x, y, batch_size=128, epochs=1, shuffle=True))\n",
    "model.save('model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(length, start):\n",
    "    \n",
    "    states = [np.zeros((1, lstm_size)) for i in range(6)]\n",
    "\n",
    "    token = np.zeros((1,1))\n",
    "    token[0,0] = start\n",
    "    text = int_to_vocab[start] + ' '\n",
    "    \n",
    "    for i in range(length):\n",
    "        \n",
    "        out = inf_model.predict([token]+states)\n",
    "        word = np.argmax(out[0][0,0,:])\n",
    "        text += int_to_vocab[word] + ' '\n",
    "        states = out[1:7]\n",
    "        token[0][0] = word\n",
    "        \n",
    "    return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = extract_text(1000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_text(text):\n",
    "    \n",
    "    punch1 = ['.', ':', '!', ';', ')', ']', '?', ',', '%']\n",
    "    for i in punch1:\n",
    "        text = text.replace(' '+i, i)\n",
    "    punch2 = ['[', '(', '$']    \n",
    "    for i in punch2:\n",
    "        text = text.replace(i+' ', i)\n",
    "    punch3 = [\"'\", '-']    \n",
    "    for i in punch3:\n",
    "        text = text.replace(' '+i+' ', i)\n",
    "        \n",
    "    text = text.split('<NEWLINE>')  \n",
    "    for line in text:\n",
    "        if len(line)\n",
    "    return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' moe_szyslak: (late) homer are carve at make your new yuh. it. ',\n",
       " ' homer_simpson: you get something something to love your creepy man? ',\n",
       " ' moe_szyslak: well to get from the man. ',\n",
       " \" moe_szyslak: oh, who's the bar? \",\n",
       " \" moe_szyslak: oh, no, who's this bar? \",\n",
       " \" moe_szyslak: (cowboys) then all right, from who's moe. \",\n",
       " ' moe_szyslak: oh, how get a man? ',\n",
       " \" moe_szyslak: (to talkin '? \",\n",
       " ' moe_szyslak: (counterfeit runt! ',\n",
       " ' moe_szyslak: what am i? am? ',\n",
       " ' moe_szyslak: oh, oh, i am a man. ',\n",
       " \" moe_szyslak: (to talkin'then.. \",\n",
       " \" moe_szyslak: (to runt, hey, you'm gonna points with the new died. \",\n",
       " \" moe_szyslak: (tummies? hello, i'm gonna candles, life, and i'm the menace, here, my droning'here. i d an creepy to you? \"]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_process_text(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
